{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify cross-page tables based on rules\n",
    "\n",
    "This sample demonstrates how to use the output of Layout model and some business rules to identify cross-page tables. Once idenfied, it can be further processed to merge these tables and keep the semantics of a table.\n",
    "\n",
    "Depending on your document format, there can be different rules applied to idenfity a cross-page table. This sample shows how to use the following rules to identify cross-page tables:\n",
    "\n",
    "- If the 2 tables appear in consecutive pages\n",
    "- And there's only page header, page footer or page number beteen them\n",
    "- And the tables have the same number of columns\n",
    "\n",
    "You can customize the rules based on your scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- An Azure AI Document Intelligence resource - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don't have.\n",
    "- Get familiar with the output structure of Layout model - complete [this quickstart](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?view=doc-intel-4.0.0&pivots=programming-language-python#layout-model) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-ai-documentintelligence python-dotenv azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads environment variables using the `dotenv` library and sets the necessary environment variables for Azure services.\n",
    "The environment variables are loaded from the `.env` file in the same directory as this notebook.\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_page_numbers(table):\n",
    "    \"\"\"\n",
    "    Returns a list of page numbers where the table appears.\n",
    "\n",
    "    Args:\n",
    "        table: The table object.\n",
    "\n",
    "    Returns:\n",
    "        A list of page numbers where the table appears.\n",
    "    \"\"\"\n",
    "    return [region.page_number for region in table.bounding_regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_span_offsets(table):\n",
    "    \"\"\"\n",
    "    Calculates the minimum and maximum offsets of a table's spans.\n",
    "\n",
    "    Args:\n",
    "        table (Table): The table object containing spans.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the minimum and maximum offsets of the table's spans.\n",
    "    \"\"\"\n",
    "    min_offset = table.spans[0].offset\n",
    "    max_offset = table.spans[0].offset + table.spans[0].length\n",
    "\n",
    "    for span in table.spans:\n",
    "        if span.offset < min_offset:\n",
    "            min_offset = span.offset\n",
    "        if span.offset + span.length > max_offset:\n",
    "            max_offset = span.offset + span.length\n",
    "\n",
    "    return min_offset, max_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_merge_table_candidates(tables):\n",
    "    \"\"\"\n",
    "    Finds the merge table candidates based on the given list of tables.\n",
    "\n",
    "    Parameters:\n",
    "    tables (list): A list of tables.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of merge table candidates, where each candidate is a dictionary with keys:\n",
    "          - pre_table_idx: The index of the first candidate table to be merged (the other table to be merged is the next one).\n",
    "          - start: The start offset of the 2nd candidate table.\n",
    "          - end: The end offset of the 1st candidate table.\n",
    "    \"\"\"\n",
    "    merge_tables_candidates = []\n",
    "    pre_table_idx = -1\n",
    "    pre_table_page = -1\n",
    "    pre_max_offset = 0\n",
    "\n",
    "    for table_idx, table in enumerate(tables):\n",
    "        min_offset, max_offset = get_table_span_offsets(table)\n",
    "        table_page = min(get_table_page_numbers(table))\n",
    "        \n",
    "        # If there is a table on the next page, it is a candidate for merging with the previous table.\n",
    "        if table_page == pre_table_page + 1:\n",
    "            pre_table = {\"pre_table_idx\": pre_table_idx, \"start\": pre_max_offset, \"end\": min_offset}\n",
    "            merge_tables_candidates.append(pre_table)\n",
    "        \n",
    "        print(f\"Table {table_idx} has offset range: {min_offset} - {max_offset} on page {table_page}\")\n",
    "\n",
    "        pre_table_idx = table_idx\n",
    "        pre_table_page = table_page\n",
    "        pre_max_offset = max_offset\n",
    "\n",
    "    return merge_tables_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_paragraph_presence(paragraphs, start, end):\n",
    "    \"\"\"\n",
    "    Checks if there is a paragraph within the specified range that is not a page header, page footer, or page number. If this were the case, the table would not be a merge table candidate.\n",
    "\n",
    "    Args:\n",
    "        paragraphs (list): List of paragraphs to check.\n",
    "        start (int): Start offset of the range.\n",
    "        end (int): End offset of the range.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if a paragraph is found within the range that meets the conditions, False otherwise.\n",
    "    \"\"\"\n",
    "    for paragraph in paragraphs:\n",
    "        for span in paragraph.spans:\n",
    "            if span.offset > start and span.offset < end:\n",
    "                # The logic role of a parapgaph is used to idenfiy if it's page header, page footer, page number, title, section heading, etc. Learn more: https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-layout?view=doc-intel-4.0.0#document-layout-analysis\n",
    "                if not hasattr(paragraph, 'role'):\n",
    "                    return True\n",
    "                elif hasattr(paragraph, 'role') and paragraph.role not in [\"pageHeader\", \"pageFooter\", \"pageNumber\"]:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cross_page_tables():\n",
    "    \"\"\"\n",
    "    Identifies and merges tables that span across multiple pages in a document.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "\n",
    "    file_path = \"<The path to your file>\"\n",
    "\n",
    "    # You can also use a URL instead of a local file with begin_analyze_document_from_url().\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\", analyze_request=f, content_type=\"application/octet-stream\"  \n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "\n",
    "    merge_tables_candidates = find_merge_table_candidates(result.tables)\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    for i, candidate in enumerate(merge_tables_candidates):\n",
    "        table_idx = candidate[\"pre_table_idx\"]\n",
    "        start = candidate[\"start\"]\n",
    "        end = candidate[\"end\"]\n",
    "        has_paragraph = check_paragraph_presence(result.paragraphs, start, end)\n",
    "        \n",
    "        # If there is no paragraph within the range and the columns of the tables match, merge the tables.\n",
    "        if not has_paragraph and result.tables[table_idx].column_count == result.tables[table_idx + 1].column_count:\n",
    "            print(f\"Merge table: {table_idx} and {table_idx + 1}\")\n",
    "            print(\"----------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_cross_page_tables()      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
