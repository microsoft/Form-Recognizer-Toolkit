{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure understanding & hierarchical document structure analysis\n",
    "\n",
    "This notebook demonstrates an example of using Azure AI Document Intelligence to ouptut detected figures and hierarchical document structure (in markdown). It will then crop the figures and send figure content (with its caption) to Azure Open AI GPT-4V model to understand the semantics. The figure description will be used to update the markdown output, which can be further used for [semantic chunking](https://aka.ms/doc-gen-ai).\n",
    "\n",
    "![Advanced document insights with figure understanding and hierarchical document structure](../media/figure-understanding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- An Azure AI Document Intelligence resource in one of the 3 preview regions: **East US**, **West US2**, **West Europe** - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don't have.\n",
    "- An Azure AI Search resource - follow [this document](https://learn.microsoft.com/azure/search/search-create-service-portal) to create one if you don't have.\n",
    "- An Azure OpenAI resource and deployments for embeddings model and chat model - follow [this document](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal) to create one if you don't have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv openai azure-ai-documentintelligence azure-identity pillow PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads environment variables using the `dotenv` library and sets the necessary environment variables for Azure services.\n",
    "The environment variables are loaded from the `.env` file in the same directory as this notebook.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import ContentFormat\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "doc_intelligence_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "doc_intelligence_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "aoai_api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_key= os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_deployment_name = 'gpt-4v' # your model deployment name for GPT-4V\n",
    "aoai_api_version = '2024-02-15-preview' # this might change in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop figure from the document (pdf or image) based on the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "import mimetypes\n",
    "\n",
    "def crop_image_from_image(image_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops an image based on a bounding box.\n",
    "\n",
    "    :param image_path: Path to the image file.\n",
    "    :param page_number: The page number of the image to crop (for TIFF format).\n",
    "    :param bounding_box: A tuple of (left, upper, right, lower) coordinates for the bounding box.\n",
    "    :return: A cropped image.\n",
    "    :rtype: PIL.Image.Image\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        if img.format == \"TIFF\":\n",
    "            # Open the TIFF image\n",
    "            img.seek(page_number)\n",
    "            img = img.copy()\n",
    "            \n",
    "        # The bounding box is expected to be in the format (left, upper, right, lower).\n",
    "        cropped_image = img.crop(bounding_box)\n",
    "        return cropped_image\n",
    "\n",
    "def crop_image_from_pdf_page(pdf_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops a region from a given page in a PDF and returns it as an image.\n",
    "\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param page_number: The page number to crop from (0-indexed).\n",
    "    :param bounding_box: A tuple of (x0, y0, x1, y1) coordinates for the bounding box.\n",
    "    :return: A PIL Image of the cropped area.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Cropping the page. The rect requires the coordinates in the format (x0, y0, x1, y1).\n",
    "    bbx = [x * 72 for x in bounding_box]\n",
    "    rect = fitz.Rect(bbx)\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72), clip=rect)\n",
    "    \n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    doc.close()\n",
    "\n",
    "    return img\n",
    "\n",
    "def crop_image_from_file(file_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crop an image from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "        page_number (int): The page number (for PDF and TIFF files, 0-indexed).\n",
    "        bounding_box (tuple): The bounding box coordinates in the format (x0, y0, x1, y1).\n",
    "\n",
    "    Returns:\n",
    "        A PIL Image of the cropped area.\n",
    "    \"\"\"\n",
    "    mime_type = mimetypes.guess_type(file_path)[0]\n",
    "    \n",
    "    if mime_type == \"application/pdf\":\n",
    "        return crop_image_from_pdf_page(file_path, page_number, bounding_box)\n",
    "    else:\n",
    "        return crop_image_from_image(file_path, page_number, bounding_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Azure OpenAI (GPT-4V model) to understand the semantics of the figure content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 2000\n",
    "\n",
    "def understand_image_with_gptv(api_base, api_key, deployment_name, api_version, image_path, caption):\n",
    "    \"\"\"\n",
    "    Generates a description for an image using the GPT-4V model.\n",
    "\n",
    "    Parameters:\n",
    "    - api_base (str): The base URL of the API.\n",
    "    - api_key (str): The API key for authentication.\n",
    "    - deployment_name (str): The name of the deployment.\n",
    "    - api_version (str): The version of the API.\n",
    "    - image_path (str): The path to the image file.\n",
    "    - caption (str): The caption for the image.\n",
    "\n",
    "    Returns:\n",
    "    - img_description (str): The generated description for the image.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        api_key=api_key,  \n",
    "        api_version=api_version,\n",
    "        base_url=f\"{api_base}/openai/deployments/{deployment_name}\"\n",
    "    )\n",
    "\n",
    "    data_url = local_image_to_data_url(image_path)\n",
    "\n",
    "    # We send both image caption and the image body to GPTv for better understanding\n",
    "    if caption != \"\":\n",
    "        response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[\n",
    "                    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "                    { \"role\": \"user\", \"content\": [  \n",
    "                        { \n",
    "                            \"type\": \"text\", \n",
    "                            \"text\": f\"Describe this image (note: it has image caption: {caption}):\" \n",
    "                        },\n",
    "                        { \n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": data_url\n",
    "                            }\n",
    "                        }\n",
    "                    ] } \n",
    "                ],\n",
    "                max_tokens=MAX_TOKENS\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "                { \"role\": \"user\", \"content\": [  \n",
    "                    { \n",
    "                        \"type\": \"text\", \n",
    "                        \"text\": \"Describe this image:\" \n",
    "                    },\n",
    "                    { \n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": data_url\n",
    "                        }\n",
    "                    }\n",
    "                ] } \n",
    "            ],\n",
    "            max_tokens=MAX_TOKENS\n",
    "        )\n",
    "\n",
    "    img_description = response.choices[0].message.content\n",
    "    \n",
    "    return img_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update markdown figure content section with the description from GPT-4V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_figure_description(md_content, img_description, idx):\n",
    "    \"\"\"\n",
    "    Updates the figure description in the Markdown content.\n",
    "\n",
    "    Args:\n",
    "        md_content (str): The original Markdown content.\n",
    "        img_description (str): The new description for the image.\n",
    "        idx (int): The index of the figure.\n",
    "\n",
    "    Returns:\n",
    "        str: The updated Markdown content with the new figure description.\n",
    "    \"\"\"\n",
    "\n",
    "    # The substring you're looking for\n",
    "    start_substring = f\"![](figures/{idx})\"\n",
    "    end_substring = \"</figure>\"\n",
    "    new_string = f\"<!-- FigureContent=\\\"{img_description}\\\" -->\"\n",
    "    \n",
    "    new_md_content = md_content\n",
    "    # Find the start and end indices of the part to replace\n",
    "    start_index = md_content.find(start_substring)\n",
    "    if start_index != -1:  # if start_substring is found\n",
    "        start_index += len(start_substring)  # move the index to the end of start_substring\n",
    "        end_index = md_content.find(end_substring, start_index)\n",
    "        if end_index != -1:  # if end_substring is found\n",
    "            # Replace the old string with the new string\n",
    "            new_md_content = md_content[:start_index] + new_string + md_content[end_index:]\n",
    "    \n",
    "    return new_md_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a document with Azure AI Document Intelligence Layout model and update figure description in the markdown output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_layout(input_file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Analyzes the layout of a document and extracts figures along with their descriptions, then update the markdown output with the new description.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): The path to the input document file.\n",
    "        output_folder (str): The path to the output folder where the cropped images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        str: The updated Markdown content with figure descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=doc_intelligence_endpoint, credential=AzureKeyCredential(doc_intelligence_key)\n",
    "    )\n",
    "\n",
    "    with open(input_file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\", analyze_request=f, content_type=\"application/octet-stream\", output_content_format=ContentFormat.MARKDOWN \n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "    md_content = result.content\n",
    "    \n",
    "    \n",
    "    if result.figures:\n",
    "        print(\"Figures:\")\n",
    "        for idx, figure in enumerate(result.figures):\n",
    "            figure_content = \"\"\n",
    "            img_description = \"\"\n",
    "            print(f\"Figure #{idx} has the following spans: {figure.spans}\")\n",
    "            for i, span in enumerate(figure.spans):\n",
    "                print(f\"Span #{i}: {span}\")\n",
    "                figure_content += md_content[span.offset:span.offset + span.length]\n",
    "            print(f\"Original figure content in markdown: {figure_content}\")\n",
    "\n",
    "            # Note: figure bounding regions currently contain both the bounding region of figure caption and figure body\n",
    "            if figure.caption:\n",
    "                caption_region = figure.caption.bounding_regions\n",
    "                print(f\"\\tCaption: {figure.caption.content}\")\n",
    "                print(f\"\\tCaption bounding region: {caption_region}\")\n",
    "                for region in figure.bounding_regions:\n",
    "                    if region not in caption_region:\n",
    "                        print(f\"\\tFigure body bounding regions: {region}\")\n",
    "                        # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "                        boundingbox = (\n",
    "                                region.polygon[0],  # x0 (left)\n",
    "                                region.polygon[1],  # y0 (top)\n",
    "                                region.polygon[4],  # x1 (right)\n",
    "                                region.polygon[5]   # y1 (bottom)\n",
    "                            )\n",
    "                        print(f\"\\tFigure body bounding box in (x0, y0, x1, y1): {boundingbox}\")\n",
    "                        cropped_image = crop_image_from_file(input_file_path, region.page_number - 1, boundingbox) # page_number is 1-indexed\n",
    "\n",
    "                        # Get the base name of the file\n",
    "                        base_name = os.path.basename(input_file_path)\n",
    "                        # Remove the file extension\n",
    "                        file_name_without_extension = os.path.splitext(base_name)[0]\n",
    "\n",
    "                        output_file = f\"{file_name_without_extension}_cropped_image_{idx}.png\"\n",
    "                        cropped_image_filename = os.path.join(output_folder, output_file)\n",
    "\n",
    "                        cropped_image.save(cropped_image_filename)\n",
    "                        print(f\"\\tFigure {idx} cropped and saved as {cropped_image_filename}\")\n",
    "                        img_description += understand_image_with_gptv(aoai_api_base, aoai_api_key, aoai_deployment_name, aoai_api_version, cropped_image_filename, figure.caption.content)\n",
    "                        print(f\"\\tDescription of figure {idx}: {img_description}\")\n",
    "            else:\n",
    "                print(\"\\tNo caption found for this figure.\")\n",
    "                for region in figure.bounding_regions:\n",
    "                    print(f\"\\tFigure body bounding regions: {region}\")\n",
    "                    # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "                    boundingbox = (\n",
    "                            region.polygon[0],  # x0 (left)\n",
    "                            region.polygon[1],  # y0 (top\n",
    "                            region.polygon[4],  # x1 (right)\n",
    "                            region.polygon[5]   # y1 (bottom)\n",
    "                        )\n",
    "                    print(f\"\\tFigure body bounding box in (x0, y0, x1, y1): {boundingbox}\")\n",
    "\n",
    "                    cropped_image = crop_image_from_file(input_file_path, region.page_number - 1, boundingbox) # page_number is 1-indexed\n",
    "\n",
    "                    # Get the base name of the file\n",
    "                    base_name = os.path.basename(input_file_path)\n",
    "                    # Remove the file extension\n",
    "                    file_name_without_extension = os.path.splitext(base_name)[0]\n",
    "\n",
    "                    output_file = f\"{file_name_without_extension}_cropped_image_{idx}.png\"\n",
    "                    cropped_image_filename = os.path.join(output_folder, output_file)\n",
    "                    # cropped_image_filename = f\"data/cropped/image_{idx}.png\"\n",
    "                    cropped_image.save(cropped_image_filename)\n",
    "                    print(f\"\\tFigure {idx} cropped and saved as {cropped_image_filename}\")\n",
    "                    img_description += understand_image_with_gptv(aoai_api_base, aoai_api_key, aoai_deployment_name, aoai_api_version, cropped_image_filename, \"\")\n",
    "                    print(f\"\\tDescription of figure {idx}: {img_description}\")\n",
    "            \n",
    "            # replace_figure_description(figure_content, img_description, idx)\n",
    "            md_content = update_figure_description(md_content, img_description, idx)\n",
    "\n",
    "    return md_content\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figures:\n",
      "Figure #0 has the following spans: [{'offset': 445, 'length': 215}]\n",
      "Span #0: {'offset': 445, 'length': 215}\n",
      "Original figure content in markdown: \n",
      "<figure>\n",
      "\n",
      "<figcaption>\n",
      "\n",
      "Figure 1: Here is a figure with text\n",
      "\n",
      "</figcaption>\n",
      "\n",
      "![](figures/0)\n",
      "\n",
      "<!-- FigureContent=\"Values 500 450 400 400 350 300 300 250 200 200 100 0 Jan Feb Mar Apr May Jun Months\" -->\n",
      "\n",
      "</figure>\n",
      "\n",
      "\n",
      "\tCaption: Figure 1: Here is a figure with text\n",
      "\tCaption bounding region: [{'pageNumber': 1, 'polygon': [1.4183, 6.8082, 3.591, 6.8082, 3.591, 6.9657, 1.4183, 6.9657]}]\n",
      "\tFigure body bounding regions: {'pageNumber': 1, 'polygon': [1.0301, 7.1098, 4.1763, 7.1074, 4.1781, 9.0873, 1.0324, 9.0891]}\n",
      "\tFigure body bounding box in (x0, y0, x1, y1): (1.0301, 7.1098, 4.1781, 9.0873)\n",
      "\tFigure 0 cropped and saved as data/cropped\\layout-sample_cropped_image_0.png\n",
      "\tDescription of figure 0: This is a bar graph displaying values over a six-month period, from January to June. Each month is represented by a colored bar with the following values:\n",
      "\n",
      "- January (orange): 200\n",
      "- February (green): 300\n",
      "- March (blue): 400\n",
      "- April (orange): 450\n",
      "- May (green): 350\n",
      "- June (blue): 250\n",
      "\n",
      "The y-axis is labeled \"Values\" with a scale from 0 to 500, incremented by 100, and the x-axis is labeled \"Months.\" Each bar's value is written at the top of the bar. The graph has a light gray arrow pointing downwards at the top right corner. The image also has a caption that reads \"Figure 1: Here is a figure with text.\"\n",
      "-------------------------------------------------------------------------------------------\n",
      "Updated markdown content with figure understanding:\n",
      "\n",
      " <!-- PageHeader=\"This is the header of the document.\" -->\n",
      "\n",
      "This is title\n",
      "===\n",
      "\n",
      "\n",
      "# 1\\. Text\n",
      "\n",
      "Latin refers to an ancient Italic language originating in the region of Latium in ancient Rome.\n",
      "\n",
      "\n",
      "# 2\\. Page Objects\n",
      "\n",
      "\n",
      "## 2.1 Table\n",
      "\n",
      "Here's a sample table below, designed to be simple for easy understand and quick reference.\n",
      "\n",
      "| Name | Corp | Remark |\n",
      "| - | - | - |\n",
      "| Foo | | |\n",
      "| Bar | Microsoft | Dummy |\n",
      "\n",
      "Table 1: This is a dummy table\n",
      "\n",
      "\n",
      "## 2.2. Figure\n",
      "\n",
      "<figure>\n",
      "\n",
      "<figcaption>\n",
      "\n",
      "Figure 1: Here is a figure with text\n",
      "\n",
      "</figcaption>\n",
      "\n",
      "![](figures/0)<!-- FigureContent=\"This is a bar graph displaying values over a six-month period, from January to June. Each month is represented by a colored bar with the following values:\n",
      "\n",
      "- January (orange): 200\n",
      "- February (green): 300\n",
      "- March (blue): 400\n",
      "- April (orange): 450\n",
      "- May (green): 350\n",
      "- June (blue): 250\n",
      "\n",
      "The y-axis is labeled \"Values\" with a scale from 0 to 500, incremented by 100, and the x-axis is labeled \"Months.\" Each bar's value is written at the top of the bar. The graph has a light gray arrow pointing downwards at the top right corner. The image also has a caption that reads \"Figure 1: Here is a figure with text.\"\" --></figure>\n",
      "\n",
      "\n",
      "\n",
      "# 3\\. Others\n",
      "\n",
      "AI Document Intelligence is an AI service that applies advanced machine learning to extract text, key-value pairs, tables, and structures from documents automatically and accurately:\n",
      " :selected:\n",
      "clear\n",
      " :selected:\n",
      "precise\n",
      " :unselected:\n",
      "vague\n",
      " :selected:\n",
      "coherent\n",
      " :unselected:\n",
      "Incomprehensible\n",
      "\n",
      "Turn documents into usable data and shift your focus to acting on information rather than compiling it. Start with prebuilt models or create custom models tailored to your documents both on premises and in the cloud with the AI Document Intelligence studio or SDK. Learn how to accelerate your business processes by automating text extraction with AI Document Intelligence. This webinar features hands-on demos for key use cases such as document processing, knowledge mining, and industry-specific AI model customization.\n",
      "\n",
      "<!-- PageFooter=\"This is the footer of the document.\" -->\n",
      "\n",
      "<!-- PageNumber=\"1 | Page\" -->\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_md_with_figure_understanding = analyze_layout(\"data/layout-sample.pdf\", \"data/cropped\")\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------\")\n",
    "print(f\"Updated markdown content with figure understanding:\\n\\n {updated_md_with_figure_understanding}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
